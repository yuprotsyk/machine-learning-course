{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Машинне навчання</h1>\n",
    "<p>Ю.С. Процик. Курс лекцій</p>\n",
    "<div align=\"right\"><em>Cформовано на основі <a href=\"https://mlcourse.ai\">відкритого курсу</a> Юрія Кашницького</em></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "uk"
   },
   "source": [
    "# <center>Тема 5. Вибір моделей та критеріїв якості</center>\n",
    "\n",
    "## План\n",
    "\n",
    "1. [Критерії якості в задачі регресії](#1.-Критерії-якості-в-задачі-регресії)\n",
    "2. [Критерії якості в задачі класифікації](#2.-Критерії-якості-в-задачі-класифікації)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "uk"
   },
   "source": [
    "## 1. Критерії якості в задачі регресії\n",
    "\n",
    "Найбільш типовими мірами якості в задачах регресії є середня квадратична (Mean Squared Error, MSE) і середня абсолютна (Mean Absolute Error, MAE) помилки:\n",
    "$$ {\\rm MSE} = \\frac{1}{\\ell}\\sum\\limits_{i=1}^{\\ell}(a(x_i)-y_i)^2; $$\n",
    "$$ {\\rm MAE} =\\frac{1}{\\ell}\\sum\\limits_{i=1}^{\\ell}|a(x_i)-y_i|. $$\n",
    "\n",
    "Середньоквадратичний функціонал сильніше штрафує за великі відхилення у порівнянні з середньоабсолютним, і тому більш чутливий до викидів. При використанні будь-якого з цих двох функціоналів може бути корисно проаналізувати, які об'єкти вносять найбільший вклад у загальну помилку — не виключено, що на цих об'єктах була допущена помилка при обчисленні ознак.\n",
    "Середньоквадратична помилка підходить для порівняння двох моделей або для контролю якості під час навчання, але не дозволяє робити висновки про те, наскільки добре дана модель розв'язує задачу. Наприклад, $\\rm MSE = 10$ є дуже поганим показником, якщо цільова змінна приймає значення від 0 до 1, і дуже хорошим, якщо цільова змінна лежить в інтервалі $(10000, 100000)$. У таких ситуаціях замість середньоквадратичної помилки корисно використовувати коефіцієнт детермінації, або коефіцієнт $R^2$:\n",
    "$$R^2 = 1 - \\frac{\\displaystyle\\frac{1}{\\ell}\\sum\\limits_{i=1}^{\\ell}(a(x_i)-y_i)^2}{\\displaystyle\\frac{1}{\\ell}\\sum\\limits_{i=1}^{\\ell}(y_i-\\overline{y})^2},$$\n",
    "\n",
    "де $\\overline{y} = \\frac{1}{\\ell}\\sum\\limits_{i=1}^{\\ell}y_i$ — середнє значення цільової змінної. Коефіцієнт детермінації вимірює частку дисперсії, що пояснюється моделлю, в загальній дисперсії цільової змінної. Фактично, дана міра якості — це нормована середньоквадратична помилка. Якщо вона близька до одиниці, то модель добре пояснює дані, якщо ж вона близька до нуля, то прогнози можна порівняти за якістю з константним прогнозом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "uk"
   },
   "source": [
    "## 2. Критерії якості в задачі класифікації\n",
    "\n",
    "### Матриця помилок\n",
    "\n",
    "Розглянемо задачу бінарної класифікації, в якій мітки належать множині $\\{0, 1\\}$. Об'єкти з міткою 1 будемо називати *позитивними*, а з міткою 0 - *негативними*. Алгоритм прогнозує приналежність кожного об'єкта до одного з класів.\n",
    "\n",
    "Перед тим як перейти до самих метрик введемо поняття *матриці помилок* (confusion matrix). Це спосіб розбити об'єкти на чотири категорії в залежності від комбінації істинної відповіді і відповіді алгоритму (див. табл. 1). \n",
    "\n",
    "<center> Таблиця 1. Матриця помилок </center>\n",
    "\n",
    "|            |       $y = 1$       |       $y = 0$       |\n",
    "|:----------:|:-------------------:|:-------------------:|\n",
    "| $a(x) = 1$ |  True Positive (**TP**) | False Positive (**FP**) |\n",
    "| $a(x) = 0$ | False Negative (**FN**) |  True Negative (**TN**) |\n",
    "\n",
    "Тут $a(x)$ - це відповідь алгоритму на об'єкті, а $y$ - справжня мітка класу на цьому об'єкті.\n",
    "Таким чином, помилки класифікації бувають двох видів: False Negative (**FN**) і False Positive (**FP**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Частка правильних відповідей (accuracy)\n",
    "\n",
    "Інтуїтивно зрозумілою, очевидною і такою, що майже не використовується метрикою є accuracy — *частка правильних відповідей* алгоритму:\n",
    "$$ \\rm{accuracy} = \\frac{TP + TN}{TP + FP + FN + TN}$$\n",
    "\n",
    "Покажемо на прикладі, що у випадку з незбалансованими класами однієї частки правильних відповідей недостатньо для оцінки якості роботи алгоритму.\n",
    "\n",
    "Припустимо, ми хочемо оцінити роботу спам-фільтра пошти. У нас є 100 НЕ-спам листів, 90 з яких наш класифікатор визначив вірно (True Negative = 90, False Positive = 10), і 10 спам-листів, 5 з яких класифікатор також визначив вірно (True Positive = 5, False Negative = 5).\n",
    "\n",
    "Тоді accuracy:\n",
    "$$ \\rm{accuracy} = \\frac{5 + 90}{5 + 10 + 5 + 90} = 0.864$$\n",
    "\n",
    "Однак якщо ми просто будемо прогнозувати, що всі листи — не-спам, то отримаємо більшу *частку правильних відповідей*:\n",
    "\n",
    "$$\\rm{accuracy} = \\frac{0 + 100}{0 + 0 + 10 + 100} = 0.909$$\n",
    "\n",
    "\n",
    "При цьому, наша модель абсолютно не володіє ніякою передбачувальною силою, так як спочатку ми хотіли визначати листи зі спамом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Точність (precision),  повнота (recall) та F-міра\n",
    "\n",
    "Набагато більш інформативними критеріями є *точність* (precision) та *повнота* (recall):\n",
    "$$ \\rm precision = \\frac{TP}{TP + FP}; $$\n",
    "\n",
    "$$ \\rm recall = \\frac{TP}{TP + FN}. $$\n",
    "\n",
    "*Точність* показує, яка частка об'єктів, виділених класифікатором як позитивні, дійсно є позитивними. *Повнота* показує, яка частина позитивних об'єктів було виділена класифікатором.\n",
    "\n",
    "<img src='../img/precision_recall.png' width=30%>\n",
    "\n",
    "Відзначимо, що точність і повнота не залежать від співвідношення розмірів класів. Навіть якщо об'єктів позитивного класу на порядки менше, ніж об'єктів негативного класу, дані показники будуть коректно відображати якість роботи алгоритму.\n",
    "\n",
    "Існує декілька способів отримати один критерій якості на основі точності і повноти. Один з них — *F-міра*, гармонійне середнє точності і повноти:\n",
    "$$ F = \\rm \\frac{2 \\cdot precision \\cdot recall}{precision + recall} $$\n",
    "\n",
    "Середнє гармонійне має важливу властивість — воно близьке до нуля, якщо хоча б один з аргументів близький до нуля. Саме тому воно є кращим, ніж середнє арифметичне (якщо алгоритм буде відносити всі об'єкти до позитивного класу, то він буде мати $\\rm recall = 1$ і $\\rm precision <\\!< 1$, а їх середнє арифметичне буде більше $1/2$, що неприпустимо).\n",
    "\n",
    "\n",
    "У багатокласових задачах, як правило, намагаються звести підрахунок якості до обчислення однієї з розглянутих вище двокласових метрик. Виділяють два підходи до такого зведення: мікро- та макро-усереднення.\n",
    "\n",
    "Нехай вибірка складається з $K$ класів. Розглянемо $K$ двокласових задач, кожна з яких полягає у відокремлені свого класу від інших, тобто цільові значення для $k$-ї задачі обчислюються як $y_i^k = [y_i = k]$. Для кожної з них можна обчислити різні характеристики (TP, FP, і т.д.) алгоритму $a^k(x) = [a(x) = k]$. При мікро-усередненні спочатку ці характеристики усереднюються по всіх класах, а потім обчислюється підсумкова двокласова метрика — наприклад, *точність*, *повнота* або *F-міра*. При макро-усередненні спочатку обчислюється підсумкова метрика для кожного класу, а потім результати усереднюються по всіх класах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Площа під кривою помилок (AUC-ROC)\n",
    "\n",
    "Припустимо, що розв'язується задача класифікації з двома класами $\\{0, 1\\}$, а алгоритм видає деяку оцінку (може, але не обов'язково, ймовірність) приналежності об'єкта до класу 1. Можна вважати, що оцінка належить відрізку $[0, 1]$. При конвертації оцінки (відповіді алгоритму) в бінарну мітку, ми повинні вибрати будь-який поріг, при якому 0 стає 1. Природним і близьким видається поріг, рівний 0.5, але він не завжди є оптимальним, наприклад, при вищезгаданій відсутності балансу класів.\n",
    "\n",
    "Одним із способів оцінити модель в цілому, не прив'язуючись до конкретного порогу, є AUC-ROC (або ROC AUC) — *площа* (Area Under Curve) *під кривою помилок* (Receiver Operating Characteristic curve). Дана крива представляє собою ламану від $(0,0)$ до $(1,1)$ в координатах False Positive Rate (**FPR**) та True Positive Rate (**TPR**):\n",
    "\n",
    "$$\\rm TPR = \\frac{TP}{TP + FN} $$\n",
    "$$\\rm FPR = \\frac{FP}{FP + TN} $$\n",
    "\n",
    "TPR нам вже відома, це *повнота*, а FPR показує, яку частку з об'єктів негативного класу алгоритм спрогнозував невірно. В ідеальному випадку, коли класифікатор не робить помилок (FPR = 0, TPR = 1) ми отримаємо площу під кривою, що дорівнює одиниці; в іншому випадку, коли класифікатор випадково видає ймовірності класів, AUC-ROC буде прямувати до 0.5, так як класифікатор видаватиме приблизно однакову кількість TP і FP. Кожна точка на графіку відповідає вибору деякого порогу. Площа під кривою в даному випадку показує якість алгоритму (більша — краще).\n",
    "\n",
    "\n",
    "Покажемо на конкретному прикладі, як будується крива.\n",
    "\n",
    "Нехай алгоритм видав оцінки, як показано в таблиці 2. Впорядкуємо рядки таблиці 2 за спаданням відповідей алгоритму — отримаємо таблицю 3. Зрозуміло, що в ідеалі її стовпець \"клас\" теж стане впорядкованим (спочатку йдуть 1, потім 0); в найгіршому випадку — порядок буде зворотний (спочатку 0, потім 1); в разі «сліпого вгадування» буде випадковий розподіл 0 і 1.\n",
    "\n",
    "<center> Таблиця 2 </center>\n",
    "\n",
    "| id | оцінка | клас |\n",
    "|:--:|:------:|:----:|\n",
    "|  1 |   0.5  |   0  |\n",
    "|  2 |   0.1  |   0  |\n",
    "|  3 |   0.2  |   0  |\n",
    "|  4 |   0.6  |   1  |\n",
    "|  5 |   0.2  |   1  |\n",
    "|  6 |   0.3  |   1  |\n",
    "|  7 |   0.0  |   0  |\n",
    "\n",
    "<center> Таблиця 3 </center>\n",
    "\n",
    "| id | оцінка | клас |\n",
    "|:--:|:------:|:----:|\n",
    "|  4 |   0.6  |   1  |\n",
    "|  1 |   0.5  |   0  |\n",
    "|  6 |   0.3  |   1  |\n",
    "|  3 |   0.2  |   0  |\n",
    "|  5 |   0.2  |   1  |\n",
    "|  2 |   0.1  |   0  |\n",
    "|  7 |   0.0  |   0  |\n",
    "\n",
    "Щоб намалювати ROC-криву, треба взяти одиничний квадрат на координатній площині (див. рис. 1), розбити його на $m$ рівних частин горизонтальними лініями і на $n$ — вертикальними, де $m$ — кількість 1 серед правильних міток тесту (в нашому прикладі $m = 3$), $n$ — кількість нулів ($n = 4$). В результаті квадрат розбивається сіткою на $m \\times n$ блоків.\n",
    "\n",
    "Тепер будемо переглядати рядки таблиці 3 зверху вниз і прорисовувати на сітці лінії, переходячи з одного вузла в інший. Стартуємо з точки $(0, 0)$. Якщо значення мітки класу в рядку, що переглядається рівне 1, то робимо крок вгору; якщо 0, то робимо крок вправо. Очевидно, що в підсумку ми потрапимо в точку $(1, 1)$, тому що зробимо в сумі $m$ кроків вгору і $n$ кроків вправо.\n",
    "\n",
    "<img src='../img/roc_1.png' width=50%>\n",
    "<center> Рисунок 1. Побудова ROC-кривої </center>\n",
    "\n",
    "На рисунку 1 (праворуч) показаний шлях для нашого прикладу — це і є ROC-крива. **Важливий момент**: якщо у декількох об'єктів значення оцінок рівні, то ми робимо крок в точку, яка на $a$ блоків вище і $b$ блоків правіше, де $a$ — кількість одиниць в групі об'єктів з одним значенням мітки, $b$ — кількість нулів в ній. \n",
    "\n",
    "Вище ми описали випадки ідеального, найгіршого і випадкового проходження міток у впорядкованій таблиці. Ідеальному відповідає ROC-крива, що проходить через точку $(0, 1)$, площа під нею дорівнює 1. Найгіршому — ROC-крива, що проходить через точку $(1, 0)$, площа під нею — 0. Випадковому — щось схоже на діагональ квадрата, площа приблизно дорівнює 0.5.\n",
    "\n",
    "<img src='../img/roc_2.png' width=50%>\n",
    "<center> Рисунок 2. ROC-криві для найкращого (AUC = 1), випадкового (AUC = 0.5) і найгіршого (AUC = 0) алгоритму.</center>\n",
    "\n",
    "Критерій AUC-ROC може бути інтерпретований як ймовірність того, що випадково обраний позитивний об'єкт буде проранжований класифікатором вище (матиме більшу ймовірність бути позитивним), ніж випадково обраний негативний об'єкт."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "ru",
   "targetLang": "uk",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
